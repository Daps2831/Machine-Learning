{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4NDiujPKM4gw5fmqfLp2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daps2831/Machine-Learning/blob/main/Week%207/Week_7_Boosting_and_Bagging_Regresi_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount File"
      ],
      "metadata": {
        "id": "4vbvli1BpDfa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcXpo9YNofB9",
        "outputId": "432b05d7-83b9-4b5b-8fe3-6a8baa05d3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ganti path sesuai lokasi file di Google Drive\n",
        "# note: dataset obesity_level diambil dari kaggle\n",
        "file_path = \"/content/drive/MyDrive/Dataset/Infrared.csv\"\n",
        "# Membaca file Excel\n",
        "df = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "VgxUhtVXpRmS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data describing and preprocessing"
      ],
      "metadata": {
        "id": "ypXNCffBpcei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan kolom kategorikal dan numerikal\n",
        "print(\"\\n--- Semua Kolom ---\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Pisahkan kolom numerikal dan kategorikal\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"\\n--- Kolom Categorikal ---\")\n",
        "print(list(categorical_cols))\n",
        "print(\"\\n--- Kolom Numerikal ---\")\n",
        "print(list(numerical_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIVhCt4iphAi",
        "outputId": "e4a426a2-3c08-4dcc-daf5-472d46df8044"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Semua Kolom ---\n",
            "['Gender', 'Age', 'Ethnicity', 'T_atm', 'Humidity', 'Distance', 'T_offset1', 'Max1R13_1', 'Max1L13_1', 'aveAllR13_1', 'aveAllL13_1', 'T_RC1', 'T_RC_Dry1', 'T_RC_Wet1', 'T_RC_Max1', 'T_LC1', 'T_LC_Dry1', 'T_LC_Wet1', 'T_LC_Max1', 'RCC1', 'LCC1', 'canthiMax1', 'canthi4Max1', 'T_FHCC1', 'T_FHRC1', 'T_FHLC1', 'T_FHBC1', 'T_FHTC1', 'T_FH_Max1', 'T_FHC_Max1', 'T_Max1', 'T_OR1', 'T_OR_Max1', 'aveOralM']\n",
            "\n",
            "--- Kolom Categorikal ---\n",
            "['Gender', 'Age', 'Ethnicity']\n",
            "\n",
            "--- Kolom Numerikal ---\n",
            "['T_atm', 'Humidity', 'Distance', 'T_offset1', 'Max1R13_1', 'Max1L13_1', 'aveAllR13_1', 'aveAllL13_1', 'T_RC1', 'T_RC_Dry1', 'T_RC_Wet1', 'T_RC_Max1', 'T_LC1', 'T_LC_Dry1', 'T_LC_Wet1', 'T_LC_Max1', 'RCC1', 'LCC1', 'canthiMax1', 'canthi4Max1', 'T_FHCC1', 'T_FHRC1', 'T_FHLC1', 'T_FHBC1', 'T_FHTC1', 'T_FH_Max1', 'T_FHC_Max1', 'T_Max1', 'T_OR1', 'T_OR_Max1', 'aveOralM']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Lihat 5 baris pertama untuk memahami isinya\n",
        "print(\"Lima baris pertama dari data:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# 3. Lihat informasi dasar (tipe data, jumlah data non-null)\n",
        "print(\"Informasi dasar dan tipe data:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# 4. Lihat ringkasan statistik untuk kolom numerik\n",
        "print(\"Ringkasan statistik data:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDKt1WKnpjfa",
        "outputId": "8f733552-40bc-416a-8f6c-479aa9f0b32d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lima baris pertama dari data:\n",
            "   Gender    Age                  Ethnicity  T_atm  Humidity  Distance  \\\n",
            "0    Male  41-50                      White   24.0      28.0       0.8   \n",
            "1  Female  31-40  Black or African-American   24.0      26.0       0.8   \n",
            "2  Female  21-30                      White   24.0      26.0       0.8   \n",
            "3  Female  21-30  Black or African-American   24.0      27.0       0.8   \n",
            "4    Male  18-20                      White   24.0      27.0       0.8   \n",
            "\n",
            "   T_offset1  Max1R13_1  Max1L13_1  aveAllR13_1  ...  T_FHRC1  T_FHLC1  \\\n",
            "0     0.7025    35.0300    35.3775      34.4000  ...  33.4775  33.3725   \n",
            "1     0.7800    34.5500    34.5200      33.9300  ...  34.0550  33.6775   \n",
            "2     0.8625    35.6525    35.5175      34.2775  ...  34.8275  34.6475   \n",
            "3     0.9300    35.2225    35.6125      34.3850  ...  34.4225  34.6550   \n",
            "4     0.8950    35.5450    35.6650      34.9100  ...  35.1600  34.3975   \n",
            "\n",
            "   T_FHBC1  T_FHTC1  T_FH_Max1  T_FHC_Max1   T_Max1    T_OR1  T_OR_Max1  \\\n",
            "0  33.4925  33.0025    34.5300     34.0075  35.6925  35.6350    35.6525   \n",
            "1  33.9700  34.0025    34.6825     34.6600  35.1750  35.0925    35.1075   \n",
            "2  34.8200  34.6700    35.3450     35.2225  35.9125  35.8600    35.8850   \n",
            "3  34.3025  34.9175    35.6025     35.3150  35.7200  34.9650    34.9825   \n",
            "4  34.6700  33.8275    35.4175     35.3725  35.8950  35.5875    35.6175   \n",
            "\n",
            "   aveOralM  \n",
            "0     36.59  \n",
            "1     37.19  \n",
            "2     37.34  \n",
            "3     37.09  \n",
            "4     37.04  \n",
            "\n",
            "[5 rows x 34 columns]\n",
            "\n",
            "========================================\n",
            "\n",
            "Informasi dasar dan tipe data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1020 entries, 0 to 1019\n",
            "Data columns (total 34 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Gender       1020 non-null   object \n",
            " 1   Age          1020 non-null   object \n",
            " 2   Ethnicity    1020 non-null   object \n",
            " 3   T_atm        1020 non-null   float64\n",
            " 4   Humidity     1020 non-null   float64\n",
            " 5   Distance     1018 non-null   float64\n",
            " 6   T_offset1    1020 non-null   float64\n",
            " 7   Max1R13_1    1020 non-null   float64\n",
            " 8   Max1L13_1    1020 non-null   float64\n",
            " 9   aveAllR13_1  1020 non-null   float64\n",
            " 10  aveAllL13_1  1020 non-null   float64\n",
            " 11  T_RC1        1020 non-null   float64\n",
            " 12  T_RC_Dry1    1020 non-null   float64\n",
            " 13  T_RC_Wet1    1020 non-null   float64\n",
            " 14  T_RC_Max1    1020 non-null   float64\n",
            " 15  T_LC1        1020 non-null   float64\n",
            " 16  T_LC_Dry1    1020 non-null   float64\n",
            " 17  T_LC_Wet1    1020 non-null   float64\n",
            " 18  T_LC_Max1    1020 non-null   float64\n",
            " 19  RCC1         1020 non-null   float64\n",
            " 20  LCC1         1020 non-null   float64\n",
            " 21  canthiMax1   1020 non-null   float64\n",
            " 22  canthi4Max1  1020 non-null   float64\n",
            " 23  T_FHCC1      1020 non-null   float64\n",
            " 24  T_FHRC1      1020 non-null   float64\n",
            " 25  T_FHLC1      1020 non-null   float64\n",
            " 26  T_FHBC1      1020 non-null   float64\n",
            " 27  T_FHTC1      1020 non-null   float64\n",
            " 28  T_FH_Max1    1020 non-null   float64\n",
            " 29  T_FHC_Max1   1020 non-null   float64\n",
            " 30  T_Max1       1020 non-null   float64\n",
            " 31  T_OR1        1020 non-null   float64\n",
            " 32  T_OR_Max1    1020 non-null   float64\n",
            " 33  aveOralM     1020 non-null   float64\n",
            "dtypes: float64(31), object(3)\n",
            "memory usage: 271.1+ KB\n",
            "\n",
            "========================================\n",
            "\n",
            "Ringkasan statistik data:\n",
            "             T_atm     Humidity     Distance    T_offset1    Max1R13_1  \\\n",
            "count  1020.000000  1020.000000  1018.000000  1020.000000  1020.000000   \n",
            "mean     24.115392    28.723039     0.729784     0.968648    35.596533   \n",
            "std       1.336338    13.071627     2.456486     0.362587     0.574888   \n",
            "min      20.200000     9.900000     0.540000    -0.590000    33.897500   \n",
            "25%      23.400000    17.600000     0.600000     0.772500    35.247500   \n",
            "50%      24.000000    26.300000     0.620000     0.940000    35.548750   \n",
            "75%      24.700000    36.200000     0.700000     1.140000    35.872500   \n",
            "max      29.100000    61.200000    79.000000     2.875000    38.405000   \n",
            "\n",
            "         Max1L13_1  aveAllR13_1  aveAllL13_1        T_RC1    T_RC_Dry1  ...  \\\n",
            "count  1020.000000  1020.000000  1020.000000  1020.000000  1020.000000  ...   \n",
            "mean     35.611474    34.888475    35.011345    35.659921    35.587143  ...   \n",
            "std       0.549760     0.718613     0.633836     0.553897     0.569278  ...   \n",
            "min      34.122500    31.770000    32.902500    33.985000    33.825000  ...   \n",
            "25%      35.271875    34.456250    34.651250    35.332500    35.249375  ...   \n",
            "50%      35.575000    34.915000    34.997500    35.602500    35.533750  ...   \n",
            "75%      35.883125    35.300000    35.363125    35.910625    35.855625  ...   \n",
            "max      38.042500    37.575000    37.680000    38.385000    38.380000  ...   \n",
            "\n",
            "           T_FHRC1      T_FHLC1      T_FHBC1      T_FHTC1    T_FH_Max1  \\\n",
            "count  1020.000000  1020.000000  1020.000000  1020.000000  1020.000000   \n",
            "mean     34.567782    34.565340    34.487701    34.577293    35.421555   \n",
            "std       0.669410     0.678663     0.668065     0.728678     0.523477   \n",
            "min      31.452500    31.657500    31.280000    31.150000    33.407500   \n",
            "25%      34.180000    34.177500    34.096875    34.225000    35.116875   \n",
            "50%      34.597500    34.602500    34.512917    34.622500    35.391250   \n",
            "75%      34.968125    34.965000    34.878125    35.012500    35.675000   \n",
            "max      37.075000    37.165000    37.212500    37.367500    38.002500   \n",
            "\n",
            "        T_FHC_Max1       T_Max1        T_OR1    T_OR_Max1     aveOralM  \n",
            "count  1020.000000  1020.000000  1020.000000  1020.000000  1020.000000  \n",
            "mean     35.094144    36.084785    35.805519    35.838277    37.028382  \n",
            "std       0.576045     0.491821     0.559258     0.559316     0.509502  \n",
            "min      32.440000    34.892500    33.802500    33.835000    35.540000  \n",
            "25%      34.756458    35.775000    35.474375    35.500000    36.777500  \n",
            "50%      35.100000    36.027500    35.790000    35.825000    36.940000  \n",
            "75%      35.415000    36.280000    36.087500    36.120625    37.140000  \n",
            "max      37.632500    38.807500    38.417500    38.455000    40.340000  \n",
            "\n",
            "[8 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek nilai yang hilang\n",
        "print(\"\\n--- Nilai Hilang ---\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"Jumlah baris sebelum menangani missing values: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxq1ICoNrpZJ",
        "outputId": "8becab3d-ab94-4164-d3c2-3c3908ead85e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Nilai Hilang ---\n",
            "Gender         0\n",
            "Age            0\n",
            "Ethnicity      0\n",
            "T_atm          0\n",
            "Humidity       0\n",
            "Distance       2\n",
            "T_offset1      0\n",
            "Max1R13_1      0\n",
            "Max1L13_1      0\n",
            "aveAllR13_1    0\n",
            "aveAllL13_1    0\n",
            "T_RC1          0\n",
            "T_RC_Dry1      0\n",
            "T_RC_Wet1      0\n",
            "T_RC_Max1      0\n",
            "T_LC1          0\n",
            "T_LC_Dry1      0\n",
            "T_LC_Wet1      0\n",
            "T_LC_Max1      0\n",
            "RCC1           0\n",
            "LCC1           0\n",
            "canthiMax1     0\n",
            "canthi4Max1    0\n",
            "T_FHCC1        0\n",
            "T_FHRC1        0\n",
            "T_FHLC1        0\n",
            "T_FHBC1        0\n",
            "T_FHTC1        0\n",
            "T_FH_Max1      0\n",
            "T_FHC_Max1     0\n",
            "T_Max1         0\n",
            "T_OR1          0\n",
            "T_OR_Max1      0\n",
            "aveOralM       0\n",
            "dtype: int64\n",
            "Jumlah baris sebelum menangani missing values: 1020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan kolom numerik dan kategorikal\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Penanganan nilai hilang pada kolom numerik dengan mean\n",
        "for col in numerical_cols:\n",
        "    if df[col].isnull().any():\n",
        "        mean_value = df[col].mean()\n",
        "        df[col] = df[col].fillna(mean_value)\n",
        "\n",
        "# Penanganan nilai hilang pada kolom kategorikal dengan 'unknown'\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().any():\n",
        "        df[col] = df[col].fillna('unknown')\n",
        "\n",
        "# Cek kembali nilai yang hilang setelah penanganan\n",
        "print(\"\\n--- Nilai Hilang Setelah Penanganan ---\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"Jumlah baris setelah menangani missing values: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnKk0TNKr9Dw",
        "outputId": "4af74996-98f8-4f80-c149-15e85191715f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Nilai Hilang Setelah Penanganan ---\n",
            "Gender         0\n",
            "Age            0\n",
            "Ethnicity      0\n",
            "T_atm          0\n",
            "Humidity       0\n",
            "Distance       0\n",
            "T_offset1      0\n",
            "Max1R13_1      0\n",
            "Max1L13_1      0\n",
            "aveAllR13_1    0\n",
            "aveAllL13_1    0\n",
            "T_RC1          0\n",
            "T_RC_Dry1      0\n",
            "T_RC_Wet1      0\n",
            "T_RC_Max1      0\n",
            "T_LC1          0\n",
            "T_LC_Dry1      0\n",
            "T_LC_Wet1      0\n",
            "T_LC_Max1      0\n",
            "RCC1           0\n",
            "LCC1           0\n",
            "canthiMax1     0\n",
            "canthi4Max1    0\n",
            "T_FHCC1        0\n",
            "T_FHRC1        0\n",
            "T_FHLC1        0\n",
            "T_FHBC1        0\n",
            "T_FHTC1        0\n",
            "T_FH_Max1      0\n",
            "T_FHC_Max1     0\n",
            "T_Max1         0\n",
            "T_OR1          0\n",
            "T_OR_Max1      0\n",
            "aveOralM       0\n",
            "dtype: int64\n",
            "Jumlah baris setelah menangani missing values: 1020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek data duplikat\n",
        "print(\"\\n--- Data Duplikat ---\")\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "print(f\"Jumlah baris duplikat: {len(duplicate_rows)}\")\n",
        "\n",
        "# Jika ada data duplikat, Anda bisa menampilkan beberapa contoh\n",
        "if not duplicate_rows.empty:\n",
        "    print(\"\\nContoh data duplikat:\")\n",
        "    print(duplicate_rows.head().to_markdown(index=False))\n",
        "\n",
        "print(f\"Jumlah baris sebelum menghapus duplikat: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXd7lsHpsEgA",
        "outputId": "5dd13a67-4a12-49b0-f887-3644dbd3eff9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Duplikat ---\n",
            "Jumlah baris duplikat: 0\n",
            "Jumlah baris sebelum menghapus duplikat: 1020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek apakah ada nilai numerik di kolom kategorikal yang spesifik\n",
        "print(\"\\n--- Mengecek nilai numerik di kolom kategorikal spesifik ---\")\n",
        "\n",
        "# Daftar kolom kategorikal yang ingin diperiksa\n",
        "specified_categorical_cols = categorical_cols\n",
        "\n",
        "for col in specified_categorical_cols:\n",
        "    if col in df.columns:\n",
        "        # Mengecek apakah tipe data kolom adalah object atau category\n",
        "        if df[col].dtype == 'object' or df[col].dtype == 'category':\n",
        "            # Mengecek apakah ada nilai yang bisa dikonversi menjadi numerik\n",
        "            # Menggunakan pd.to_numeric dengan errors='coerce' akan mengganti nilai non-numerik menjadi NaN\n",
        "            numeric_check = pd.to_numeric(df[col], errors='coerce')\n",
        "            # Jika ada nilai yang *tidak* menjadi NaN setelah konversi, berarti ada nilai numerik\n",
        "            if numeric_check.notna().any():\n",
        "                print(f\"Kolom '{col}': Ditemukan nilai yang bisa dikonversi menjadi numerik.\")\n",
        "                # Anda bisa menampilkan contoh nilai yang terpengaruh jika diinginkan\n",
        "                print(df[col][numeric_check.notna()].unique())\n",
        "            else:\n",
        "                print(f\"Kolom '{col}': Tidak ditemukan nilai yang bisa dikonversi menjadi numerik.\")\n",
        "        else:\n",
        "            print(f\"Kolom '{col}': Bukan merupakan tipe data kategorikal (object atau category).\")\n",
        "    else:\n",
        "        print(f\"Kolom '{col}': Tidak ditemukan dalam DataFrame.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC_W9C64sNCw",
        "outputId": "78d43773-54f3-42a8-def2-719642b782ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mengecek nilai numerik di kolom kategorikal spesifik ---\n",
            "Kolom 'Gender': Tidak ditemukan nilai yang bisa dikonversi menjadi numerik.\n",
            "Kolom 'Age': Tidak ditemukan nilai yang bisa dikonversi menjadi numerik.\n",
            "Kolom 'Ethnicity': Tidak ditemukan nilai yang bisa dikonversi menjadi numerik.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: buatkan kode apabila ada nilai pada kolom kategorikal yang aneh atau tidak pada umumnya\n",
        "\n",
        "# Fungsi untuk mengecek nilai aneh/tidak umum pada kolom kategorikal\n",
        "def check_uncommon_categorical_values(df, categorical_cols):\n",
        "    print(\"\\n--- Mengecek nilai aneh/tidak umum pada kolom kategorikal ---\")\n",
        "    for col in categorical_cols:\n",
        "        print(f\"\\nKolom: {col}\")\n",
        "        # Mendapatkan nilai unik dan hitungannya\n",
        "        value_counts = df[col].value_counts()\n",
        "        print(f\"Jumlah nilai unik: {len(value_counts)}\")\n",
        "        print(\"Top 10 nilai unik dan hitungannya:\")\n",
        "        print(value_counts.head(10).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "        # Anda bisa menambahkan logika tambahan di sini untuk mengidentifikasi \"nilai aneh\"\n",
        "        # Contoh: nilai yang muncul sangat jarang (frekuensi rendah)\n",
        "        # Tentukan threshold frekuensi rendah, misal kurang dari 0.1% dari total data\n",
        "        threshold = 0.001 * len(df)\n",
        "        uncommon_values = value_counts[value_counts < threshold]\n",
        "\n",
        "        if not uncommon_values.empty:\n",
        "            print(f\"\\nDitemukan nilai dengan frekuensi rendah (kurang dari {threshold:.0f} baris):\")\n",
        "            print(uncommon_values.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "        else:\n",
        "            print(\"\\nTidak ditemukan nilai dengan frekuensi rendah.\")\n",
        "\n",
        "# Panggil fungsi untuk mengecek kolom kategorikal\n",
        "check_uncommon_categorical_values(df, categorical_cols)\n",
        "\n",
        "# Jika Anda ingin menangani nilai aneh ini, Anda bisa mempertimbangkan beberapa pendekatan:\n",
        "# 1. Mengganti nilai aneh dengan nilai yang paling sering muncul (mode)\n",
        "# 2. Mengganti nilai aneh dengan 'Other' atau 'Unknown'\n",
        "# 3. Menghapus baris yang mengandung nilai aneh (hati-hati, bisa mengurangi jumlah data signifikan)\n",
        "# 4. Mengelompokkan nilai aneh ke dalam kategori yang lebih besar\n",
        "\n",
        "# Contoh penanganan: Mengganti nilai aneh dengan 'Other' jika frekuensinya di bawah threshold\n",
        "def handle_uncommon_categorical_values(df, col, threshold_ratio=0.01):\n",
        "    value_counts = df[col].value_counts()\n",
        "    threshold = threshold_ratio * len(df)\n",
        "    uncommon_values = value_counts[value_counts < threshold].index.tolist()\n",
        "\n",
        "    if uncommon_values:\n",
        "        print(f\"\\nMenangani nilai aneh di kolom '{col}': Mengganti {len(uncommon_values)} nilai dengan 'Other'.\")\n",
        "        df[col] = df[col].replace(uncommon_values, 'Other')\n",
        "        print(f\"Nilai unik di kolom '{col}' setelah penanganan:\")\n",
        "        print(df[col].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "    else:\n",
        "        print(f\"\\nKolom '{col}': Tidak ada nilai aneh untuk ditangani dengan threshold {threshold_ratio}.\")\n",
        "    return df\n",
        "\n",
        "# # Contoh penerapan penanganan (opsional, jalankan jika Anda ingin menangani nilai aneh)\n",
        "# # Tentukan threshold_ratio yang sesuai\n",
        "# threshold_ratio_for_handling = 0.01\n",
        "# for col in categorical_cols:\n",
        "#      df = handle_uncommon_categorical_values(df, col, threshold_ratio=threshold_ratio_for_handling)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1rokcjlsXHY",
        "outputId": "85707731-4b45-440f-e5ca-c7e26c094270"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mengecek nilai aneh/tidak umum pada kolom kategorikal ---\n",
            "\n",
            "Kolom: Gender\n",
            "Jumlah nilai unik: 2\n",
            "Top 10 nilai unik dan hitungannya:\n",
            "| Gender   | count   |\n",
            "|:---------|:--------|\n",
            "| Female   | 606     |\n",
            "| Male     | 414     |\n",
            "\n",
            "Tidak ditemukan nilai dengan frekuensi rendah.\n",
            "\n",
            "Kolom: Age\n",
            "Jumlah nilai unik: 8\n",
            "Top 10 nilai unik dan hitungannya:\n",
            "| Age   | count   |\n",
            "|:------|:--------|\n",
            "| 18-20 | 534     |\n",
            "| 21-25 | 355     |\n",
            "| 26-30 | 67      |\n",
            "| 31-40 | 31      |\n",
            "| 51-60 | 11      |\n",
            "| 21-30 | 10      |\n",
            "| 41-50 | 9       |\n",
            "| >60   | 3       |\n",
            "\n",
            "Tidak ditemukan nilai dengan frekuensi rendah.\n",
            "\n",
            "Kolom: Ethnicity\n",
            "Jumlah nilai unik: 6\n",
            "Top 10 nilai unik dan hitungannya:\n",
            "| Ethnicity                         | count   |\n",
            "|:----------------------------------|:--------|\n",
            "| White                             | 506     |\n",
            "| Asian                             | 260     |\n",
            "| Black or African-American         | 143     |\n",
            "| Hispanic/Latino                   | 57      |\n",
            "| Multiracial                       | 50      |\n",
            "| American Indian or Alaskan Native | 4       |\n",
            "\n",
            "Tidak ditemukan nilai dengan frekuensi rendah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Mengecek nilai kategorikal pada kolom numerik ---\")\n",
        "\n",
        "# Daftar kolom numerik yang ingin diperiksa\n",
        "specified_numerical_cols = numerical_cols\n",
        "\n",
        "for col in specified_numerical_cols:\n",
        "    if col in df.columns:\n",
        "        # Mengecek apakah tipe data kolom adalah numerik (int, float)\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            # Menggunakan pd.to_numeric dengan errors='coerce' untuk mengidentifikasi nilai non-numerik\n",
        "            # Nilai yang tidak bisa dikonversi menjadi numerik akan menjadi NaN\n",
        "            numeric_check = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "            # Menemukan nilai-nilai asli di kolom df[col] di mana numeric_check adalah NaN\n",
        "            non_numeric_values = df[col][numeric_check.isna()].unique()\n",
        "\n",
        "            if len(non_numeric_values) > 0:\n",
        "                print(f\"Kolom '{col}': Ditemukan nilai non-numerik (kategorikal/string):\")\n",
        "                print(non_numeric_values)\n",
        "            else:\n",
        "                print(f\"Kolom '{col}': Tidak ditemukan nilai non-numerik.\")\n",
        "        else:\n",
        "            print(f\"Kolom '{col}': Bukan merupakan tipe data numerik.\")\n",
        "    else:\n",
        "        print(f\"Kolom '{col}': Tidak ditemukan dalam DataFrame.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwg4F9Pyso8Q",
        "outputId": "194faaa5-de8f-40e2-fb6f-373fa1d63aeb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mengecek nilai kategorikal pada kolom numerik ---\n",
            "Kolom 'T_atm': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'Humidity': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'Distance': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_offset1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'Max1R13_1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'Max1L13_1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'aveAllR13_1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'aveAllL13_1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_RC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_RC_Dry1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_RC_Wet1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_RC_Max1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_LC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_LC_Dry1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_LC_Wet1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_LC_Max1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'RCC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'LCC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'canthiMax1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'canthi4Max1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_FHCC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_FHRC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_FHLC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_FHBC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_FHTC1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_FH_Max1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_FHC_Max1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_Max1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_OR1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'T_OR_Max1': Tidak ditemukan nilai non-numerik.\n",
            "Kolom 'aveOralM': Tidak ditemukan nilai non-numerik.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: buatkan Encoding Variabel Kategorikal\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Pilih kolom kategorikal yang ingin di-encode\n",
        "specified_categorical_cols = categorical_cols # Ganti dengan nama kolom kategorikal Anda\n",
        "\n",
        "# Buat salinan dataframe agar tidak mengubah dataframe asli\n",
        "df_encoded_only = df.copy()\n",
        "\n",
        "# Lakukan encoding menggunakan LabelEncoder\n",
        "for col in specified_categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded_only[col] = le.fit_transform(df_encoded_only[col])\n",
        "\n",
        "# Tampilkan beberapa baris pertama setelah encoding\n",
        "print(\"\\n--- Dataframe Setelah Encoding Variabel Kategorikal ---\")\n",
        "print(df_encoded_only.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCctpAbZtBip",
        "outputId": "bfd4ff62-27d1-4d45-a7bb-5ad121c476ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Dataframe Setelah Encoding Variabel Kategorikal ---\n",
            "   Gender  Age  Ethnicity  T_atm  Humidity  Distance  T_offset1  Max1R13_1  \\\n",
            "0       1    5          5   24.0      28.0       0.8     0.7025    35.0300   \n",
            "1       0    4          2   24.0      26.0       0.8     0.7800    34.5500   \n",
            "2       0    2          5   24.0      26.0       0.8     0.8625    35.6525   \n",
            "3       0    2          2   24.0      27.0       0.8     0.9300    35.2225   \n",
            "4       1    0          5   24.0      27.0       0.8     0.8950    35.5450   \n",
            "\n",
            "   Max1L13_1  aveAllR13_1  ...  T_FHRC1  T_FHLC1  T_FHBC1  T_FHTC1  T_FH_Max1  \\\n",
            "0    35.3775      34.4000  ...  33.4775  33.3725  33.4925  33.0025    34.5300   \n",
            "1    34.5200      33.9300  ...  34.0550  33.6775  33.9700  34.0025    34.6825   \n",
            "2    35.5175      34.2775  ...  34.8275  34.6475  34.8200  34.6700    35.3450   \n",
            "3    35.6125      34.3850  ...  34.4225  34.6550  34.3025  34.9175    35.6025   \n",
            "4    35.6650      34.9100  ...  35.1600  34.3975  34.6700  33.8275    35.4175   \n",
            "\n",
            "   T_FHC_Max1   T_Max1    T_OR1  T_OR_Max1  aveOralM  \n",
            "0     34.0075  35.6925  35.6350    35.6525     36.59  \n",
            "1     34.6600  35.1750  35.0925    35.1075     37.19  \n",
            "2     35.2225  35.9125  35.8600    35.8850     37.34  \n",
            "3     35.3150  35.7200  34.9650    34.9825     37.09  \n",
            "4     35.3725  35.8950  35.5875    35.6175     37.04  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 2. Menentukan Fitur (X) dan Target (y)\n",
        "target_column = 'aveOralM'\n",
        "if target_column not in df_encoded_only.columns:\n",
        "    print(f\"Error: Kolom target '{target_column}' tidak ditemukan.\")\n",
        "    print(f\"Kolom yang tersedia: {df.columns.tolist()}\")\n",
        "else:\n",
        "    y = df_encoded_only[target_column]\n",
        "    X = df_encoded_only.drop(target_column, axis=1)\n",
        "\n",
        "    print(\"✓ Fitur (X) dan Target (y) berhasil dipisahkan.\")\n",
        "    print(f\"  - Target (y): '{target_column}'\")\n",
        "    print(f\"  - Jumlah Fitur (X): {X.shape[1]} kolom\")\n",
        "    print(f\"  - Jumlah Total Sampel: {df.shape[0]} baris\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # 3. Membagi Data menjadi Data Latih dan Data Uji\n",
        "    # Menggunakan stratify untuk menjaga proporsi kelas, penting untuk klasifikasi.\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "        print(\"✓ Data berhasil dibagi (80% latih, 20% uji) menggunakan stratify.\")\n",
        "    except ValueError:\n",
        "        print(\"Peringatan: Gagal menggunakan 'stratify'. Mungkin karena beberapa kelas hanya punya 1 anggota.\")\n",
        "        print(\"Mencoba membagi data tanpa 'stratify'...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        print(\"✓ Data berhasil dibagi (80% latih, 20% uji) tanpa stratify.\")\n",
        "\n",
        "    print(f\"  - Ukuran X_train: {X_train.shape}\")\n",
        "    print(f\"  - Ukuran X_test:  {X_test.shape}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # 4. Penskalaan Fitur (Feature Scaling)\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Latih scaler HANYA pada data latih (X_train) untuk menghindari kebocoran data\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Gunakan scaler yang sudah dilatih untuk mengubah data uji (X_test)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(\"✓ Penskalaan fitur berhasil.\")\n",
        "    print(\"  - Variabel 'X_train_scaled' dan 'X_test_scaled' telah dibuat.\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    print(\"🎉 PREPROCESSING SELESAI 🎉\")\n",
        "    print(\"Data Anda sekarang siap untuk pemodelan.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpI8hZZpqtnh",
        "outputId": "382ef730-3f23-403a-fceb-55eaa60fdb42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Fitur (X) dan Target (y) berhasil dipisahkan.\n",
            "  - Target (y): 'aveOralM'\n",
            "  - Jumlah Fitur (X): 33 kolom\n",
            "  - Jumlah Total Sampel: 1020 baris\n",
            "----------------------------------------\n",
            "Peringatan: Gagal menggunakan 'stratify'. Mungkin karena beberapa kelas hanya punya 1 anggota.\n",
            "Mencoba membagi data tanpa 'stratify'...\n",
            "✓ Data berhasil dibagi (80% latih, 20% uji) tanpa stratify.\n",
            "  - Ukuran X_train: (816, 33)\n",
            "  - Ukuran X_test:  (204, 33)\n",
            "----------------------------------------\n",
            "✓ Penskalaan fitur berhasil.\n",
            "  - Variabel 'X_train_scaled' dan 'X_test_scaled' telah dibuat.\n",
            "----------------------------------------\n",
            "🎉 PREPROCESSING SELESAI 🎉\n",
            "Data Anda sekarang siap untuk pemodelan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "m0DMK0TfNkhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import library yang diperlukan\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "# --- Model Boosting (Gradient Boosting) ---\n",
        "print(\"\\n\" + \"=\"*20 + \" MODEL BOOSTING (GRADIENT BOOSTING) \" + \"=\"*20)\n",
        "\n",
        "# Inisialisasi model Gradient Boosting Regressor\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Latih model pada data latih yang sudah diskalakan\n",
        "print(\"\\nMelatih model Gradient Boosting...\")\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "print(\"Pelatihan Gradient Boosting selesai.\")\n",
        "\n",
        "# Lakukan prediksi pada data uji yang sudah diskalakan\n",
        "y_pred_gb = gb_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluasi model\n",
        "print(\"\\n--- Evaluasi Model Gradient Boosting ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_gb):.4f}\")\n",
        "print(f\"R-squared (R2): {r2_score(y_test, y_pred_gb):.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred_gb):.4f}\")\n",
        "\n",
        "\n",
        "# --- Model Bagging (Random Forest) ---\n",
        "print(\"\\n\" + \"=\"*20 + \" MODEL BAGGING (RANDOM FOREST) \" + \"=\"*20)\n",
        "\n",
        "# Inisialisasi model Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Latih model pada data latih yang sudah diskalakan\n",
        "print(\"\\nMelatih model Random Forest...\")\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "print(\"Pelatihan Random Forest selesai.\")\n",
        "\n",
        "# Lakukan prediksi pada data uji yang sudah diskalakan\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluasi model\n",
        "print(\"\\n--- Evaluasi Model Random Forest ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"R-squared (R2): {r2_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
        "\n",
        "\n",
        "# --- Opsional: Evaluasi Cross-Validation for Gradient Boosting ---\n",
        "print(\"\\n\" + \"=\"*15 + \" CROSS-VALIDATION (GRADIENT BOOSTING) \" + \"=\"*15)\n",
        "print(\"\\nMelakukan Cross-Validation untuk Gradient Boosting...\")\n",
        "\n",
        "# Lakukan cross-validation\n",
        "scores_gb_cv = cross_val_score(gb_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error') # Use appropriate metric\n",
        "\n",
        "print(f\"Skor Cross-Validation (Negative MSE) (5-fold) untuk Gradient Boosting: {scores_gb_cv}\")\n",
        "print(f\"Rata-rata Negative MSE Cross-Validation: {scores_gb_cv.mean():.4f}\")\n",
        "print(f\"Rata-rata MSE Cross-Validation: {-scores_gb_cv.mean():.4f}\")\n",
        "print(f\"Standar Deviasi Negative MSE Cross-Validation: {scores_gb_cv.std():.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n🎉 PEMODELAN SELESAI 🎉\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmV4NnTUNnOZ",
        "outputId": "851341f2-430a-4764-c641-5d619785801d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== MODEL BOOSTING (GRADIENT BOOSTING) ====================\n",
            "\n",
            "Melatih model Gradient Boosting...\n",
            "Pelatihan Gradient Boosting selesai.\n",
            "\n",
            "--- Evaluasi Model Gradient Boosting ---\n",
            "Mean Squared Error (MSE): 0.0493\n",
            "R-squared (R2): 0.7657\n",
            "Mean Absolute Error (MAE): 0.1748\n",
            "\n",
            "==================== MODEL BAGGING (RANDOM FOREST) ====================\n",
            "\n",
            "Melatih model Random Forest...\n",
            "Pelatihan Random Forest selesai.\n",
            "\n",
            "--- Evaluasi Model Random Forest ---\n",
            "Mean Squared Error (MSE): 0.0570\n",
            "R-squared (R2): 0.7292\n",
            "Mean Absolute Error (MAE): 0.1828\n",
            "\n",
            "=============== CROSS-VALIDATION (GRADIENT BOOSTING) ===============\n",
            "\n",
            "Melakukan Cross-Validation untuk Gradient Boosting...\n",
            "Skor Cross-Validation (Negative MSE) (5-fold) untuk Gradient Boosting: [-0.05918371 -0.05311762 -0.06781661 -0.08068838 -0.07485549]\n",
            "Rata-rata Negative MSE Cross-Validation: -0.0671\n",
            "Rata-rata MSE Cross-Validation: 0.0671\n",
            "Standar Deviasi Negative MSE Cross-Validation: 0.0100\n",
            "\n",
            "🎉 PEMODELAN SELESAI 🎉\n"
          ]
        }
      ]
    }
  ]
}